{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage-II Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Input, merge\n",
    "from keras.layers import Reshape,LeakyReLU,ZeroPadding2D\n",
    "from keras.layers.core import Activation, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import UpSampling2D\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, Deconvolution2D\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers import Input, merge, Convolution2D, MaxPooling2D, UpSampling2D\n",
    "from keras.optimizers import SGD, Adagrad\n",
    "from PIL import Image\n",
    "from keras import backend as K\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.objectives import binary_crossentropy\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import scipy.misc as im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "channels = 3\n",
    "\n",
    "def convolution(inputs,filters,step,stride=2,Normal=True):\n",
    "    encoder = ZeroPadding2D(padding=(1,1))(inputs)\n",
    "    encoder = Convolution2D(filters,4,4,subsample=(stride,stride),name='conv_%d'%step)(encoder)\n",
    "    if Normal:\n",
    "        encoder = BatchNormalization(name='CBat_%d'%step)(encoder)\n",
    "    encoder = LeakyReLU(alpha=0.2,name='CLRelu_%d'%step)(encoder)\n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deconvolution(inputs,filters,step,dropout):\n",
    "    _,height,width,_ = (inputs.get_shape()).as_list()\n",
    "    decoder = Deconvolution2D(filters,4,4,\n",
    "                              output_shape=(None,2*height,2*width,filters),\n",
    "                              subsample=(2,2),\n",
    "                              border_mode='same',\n",
    "                              name='Deconv_%d' % (8-step))(inputs)\n",
    "    decoder = BatchNormalization(name='DBat_%d' % (8-step))(decoder)\n",
    "    if step == 8:\n",
    "        decoder = Activation(activation='tanh')(decoder)\n",
    "    else:\n",
    "        decoder = LeakyReLU(alpha=0.2,name='DLRelu_%d' % (8-step))(decoder)   \n",
    "    if dropout[step-1] > 0:\n",
    "        decoder = Dropout(dropout[step-1])(decoder)\n",
    "    return decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator_model():\n",
    "    # Dimensions of image\n",
    "    img_x = 512\n",
    "    img_y = 512\n",
    "    g_inputs = Input(shape=(img_x,img_y,3))\n",
    "    encoder_filter = [64,128,256,512,512,512,512]\n",
    "    Encoder = []\n",
    "\n",
    "    nb_layer = len(encoder_filter)\n",
    "\n",
    "    decoder_filter = encoder_filter[::-1]\n",
    "    dropout = [0.5,0.5,0.5,0,0,0,0,0]\n",
    "\n",
    "    for i in range(nb_layer):\n",
    "        if i == 0:\n",
    "            encoder = convolution(g_inputs,encoder_filter[i],i+1)\n",
    "        else:\n",
    "            encoder = convolution(encoder,encoder_filter[i],i+1)\n",
    "        Encoder.append(encoder)     \n",
    "        \n",
    "    #Middle layer...\n",
    "    middle = convolution(Encoder[-1],512,8)\n",
    "    \n",
    "    #Buliding decoder layers...\n",
    "    for j in range(nb_layer):\n",
    "        if j == 0:\n",
    "            decoder = deconvolution(middle,decoder_filter[j],j+1,dropout)\n",
    "        else:\n",
    "            decoder = merge([decoder,Encoder[nb_layer-j]],mode='concat',concat_axis=-1)\n",
    "            decoder = deconvolution(decoder,decoder_filter[j],j+1,dropout)\n",
    "            \n",
    "    #Generate original size's originals\n",
    "    g_output = merge([decoder,Encoder[0]],mode='concat',concat_axis=-1)\n",
    "    g_output = deconvolution(g_output,3,8,dropout)\n",
    "    \n",
    "    model = Model(g_inputs,g_output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discriminator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator_model():\n",
    "    inputs = Input(shape=(img_cols,img_rows,channels*2))\n",
    "    d = ZeroPadding2D(padding=(1,1))(inputs)\n",
    "    d = Convolution2D(64,4,4,subsample=(2,2))(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    \n",
    "    d = ZeroPadding2D(padding=(1,1))(d)\n",
    "    d = Convolution2D(128,4,4,subsample=(2,2))(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    \n",
    "    d = ZeroPadding2D(padding=(1,1))(d)\n",
    "    d = Convolution2D(256,4,4,subsample=(2,2))(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    \n",
    "    d = ZeroPadding2D(padding=(1,1))(d)\n",
    "    d = Convolution2D(512,4,4,subsample=(1,1))(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    \n",
    "    d = ZeroPadding2D(padding=(1,1))(d)\n",
    "    # Sigmoid actiation \n",
    "    d = Convolution2D(1,4,4,subsample=(1,1),activation='sigmoid')(d)\n",
    "    model = Model(inputs,d)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator_containing_discriminator(generator, discriminator):\n",
    "    inputs = Input((img_cols, img_rows,channels))\n",
    "    x_generator = generator(inputs)\n",
    "    \n",
    "    merged = merge([inputs, x_generator], mode='concat',concat_axis=-1)\n",
    "    discriminator.trainable = False\n",
    "    x_discriminator = discriminator(merged)\n",
    "    \n",
    "    model = Model(inputs,[x_generator,x_discriminator])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_original(generator,output,e):\n",
    "    original = generator.predict(output)\n",
    "    original = np.squeeze(original,axis=0)\n",
    "    output = np.squeeze(output,axis=0)\n",
    "    im.imsave('output_%d.png' % e,output)\n",
    "    im.imsave('original_%d.png' % e,original)\n",
    "\n",
    "np.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator_on_generator_loss(y_true,y_pred):\n",
    "    # Cross entropy loss function used\n",
    "    return K.mean(K.binary_crossentropy(y_pred,y_true), axis=(1,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator_l1_loss(y_true,y_pred):\n",
    "    # Loss is caclulated by computing the difference between true and pred images\n",
    "    return K.mean(K.abs(y_pred - y_true),axis=(1,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs,batchsize):\n",
    "    # Loads images from .npy files\n",
    "    original = np.load('original.npy')\n",
    "    output = np.load('output.npy')\n",
    "    original = original.astype('float32')\n",
    "    output = output.astype('float32')\n",
    "    # Processes image as [0,1]\n",
    "    original = (original - 127.5) / 127.5\n",
    "    output = (output - 127.5) / 127.5\n",
    "    batchCount = original.shape[0] / batchsize\n",
    "    print 'Epochs',epochs\n",
    "    print 'Bathc_size',batchsize\n",
    "    print 'Batches per epoch',batchCount\n",
    "    generator = generator_model()\n",
    "    discriminator = discriminator_model()\n",
    "    gan = generator_containing_discriminator(generator,discriminator)\n",
    "    generator.compile(loss=generator_l1_loss, optimizer='RMSprop')\n",
    "    gan.compile(loss=[generator_l1_loss,discriminator_on_generator_loss] , optimizer='RMSprop')\n",
    "    discriminator.trainable = True\n",
    "    discriminator.compile(loss=discriminator_on_generator_loss, optimizer='RMSprop')\n",
    "    G_loss = []\n",
    "    D_loss = []\n",
    "    for e in xrange(1,epochs+1):\n",
    "        print '-'*15 , 'Epoch %d' % e , '-'*15\n",
    "        for _ in tqdm(xrange(batchCount)):\n",
    "            random_number = np.random.randint(1,original.shape[0],size=batchsize)\n",
    "            batch_original = original[random_number]\n",
    "            batch_output = output[random_number]\n",
    "            batch_output2 = np.tile(batch_output,(2,1,1,1))\n",
    "            y_dis = np.zeros((2*batchsize,30,30,1))\n",
    "            y_dis[:batchsize] = 1.0\n",
    "            generated_original = generator.predict(batch_output)\n",
    "            # Default is concat first dimension\n",
    "            concat_original = np.concatenate((batch_original,generated_original))\n",
    "            \n",
    "            dis_input = np.concatenate((concat_original,batch_output2),axis=-1)\n",
    "            dloss = discriminator.train_on_batch(dis_input,y_dis)\n",
    "            random_number = np.random.randint(1,original.shape[0],size=batchsize)\n",
    "            train_output = output[random_number]\n",
    "            batch_original = original[random_number]\n",
    "            y_gener = np.ones((batchsize,30,30,1))\n",
    "            discriminator.trainable = False\n",
    "            gloss = gan.train_on_batch(train_output,[batch_original,y_gener])\n",
    "            discriminator.trainable = True\n",
    "        G_loss.append(gloss)\n",
    "        D_loss.append(dloss)\n",
    "        if e % 50 == 0 or e == 1:\n",
    "            generate_original(generator,output[0:1],e)\n",
    "            # Saves weights in h5 file\n",
    "            generator.save('Model_para/pix2pix_g_epoch_%d.h5' % e)\n",
    "            discriminator.save('Model_para/pix2pix_d_epoch_%d.h5' % e)\n",
    "            gan.save('Model_para/pix2pix_gan_epoch_%d.h5' % e)\n",
    "    D_loss = np.array(D_loss)\n",
    "    G_loss = np.array(G_loss)\n",
    "    np.save('Model_para/dloss.npy',D_loss)\n",
    "    np.save('Model_para/gloss.npy',G_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters:\n",
    "epochs = 100\n",
    "bz = 32\n",
    "train(epochs,bz)\n",
    "g = generator_model()\n",
    "d = discriminator_model()\n",
    "gan = generator_containing_discriminator(g,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
